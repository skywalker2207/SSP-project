{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "import scipy.io.wavfile as wave\n",
    "from scipy.fftpack import fft, ifft, fftshift\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from sklearn import mixture\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import json\n",
    "from scipy.io import loadmat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matlab Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matlab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Dev\\AccentDetection\\GMM.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Dev/AccentDetection/GMM.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatlab\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Dev/AccentDetection/GMM.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m eng \u001b[39m=\u001b[39m matlab\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39mstart_matlab()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matlab'"
     ]
    }
   ],
   "source": [
    "import matlab.engine\n",
    "eng = matlab.engine.start_matlab()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_mixtures = 7\n",
    "max_iterations = 200\n",
    "#calc_deltas=True\n",
    "#sr=8000\n",
    "#hop_length=int(0.005*sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(train_data_path,feat_train_path,trained_model_path):\n",
    "  all_speakers=glob.glob(train_data_path+'*')\n",
    "  directory=feat_train_path\n",
    "  if not os.path.exists(directory):\n",
    "      os.makedirs(directory)\n",
    "      \n",
    "  directory=trained_model_path\n",
    "  if not os.path.exists(directory):\n",
    "      os.makedirs(directory)\n",
    "\n",
    "      \n",
    "  for itr1 in range(0,len(all_speakers)):\n",
    "      mp3 = glob.glob(all_speakers[itr1]+'/*.mp3')\n",
    "      for itr3 in range(0,len(mp3)):\n",
    "        sound = AudioSegment.from_mp3(mp3[itr1])\n",
    "        sound.export(all_speakers[itr1]+'/'+'.wav', format=\"wav\")\n",
    "        \n",
    "      wavs=glob.glob(all_speakers[itr1]+'/*.wav')\n",
    "      \n",
    "      spk=(all_speakers[itr1]).split(\"/\")[-1]\n",
    "      \n",
    "      if not os.path.exists(directory):\n",
    "          os.makedirs(directory)\n",
    "      \n",
    "      final_feat=np.empty([0, 39])\n",
    "      \n",
    "      for itr2 in range(0,len(wavs)):\n",
    "\n",
    "          \n",
    "          final_feat = eng.prosody(wavs[itr2])\n",
    "\n",
    "          print(final_feat.shape)\n",
    "      print(spk)    \n",
    "      np.savetxt(feat_train_path+spk+\"_all_features.txt\", final_feat, delimiter=\",\")\n",
    "\n",
    "      try:\n",
    "          gmm = mixture.GaussianMixture(n_components=n_mixtures, covariance_type='diag' , max_iter = max_iterations ).fit(final_feat)\n",
    "      except:\n",
    "          print(\"ERROR : Error while training model for file \"+spk)\n",
    "          \n",
    "      try:\n",
    "          joblib.dump(gmm,trained_model_path+spk+'.pkl')\n",
    "      except:\n",
    "          print(\"ERROR : Error while saving model for \"+spk)\n",
    "          \n",
    "\n",
    "  print(\"Training Completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(test_data_path,feat_test,trained_model_path):\n",
    "    # train feature extraction\n",
    "  all_speakers=glob.glob(test_data_path+'*')\n",
    "\n",
    "  import os\n",
    "  directory=feat_test\n",
    "  if not os.path.exists(directory):\n",
    "      os.makedirs(directory)\n",
    "\n",
    "  speakers = { all_speakers[k]:k for k in range(len(all_speakers)) }\n",
    "\n",
    "  num_test_cases={}\n",
    "  tct={}\n",
    "  for e in speakers:\n",
    "      num_test_cases[e.replace(test_data_path,'')]=len(os.listdir(e))-1\n",
    "      tct[e.replace(test_data_path,'')]=0\n",
    "\n",
    "  print(num_test_cases)\n",
    "\n",
    "  spk_names = { all_speakers[k].replace(test_data_path,''):k for k in range(len(all_speakers)) }\n",
    "\n",
    "  total_speakers=len(num_test_cases)\n",
    "\n",
    "  confusion_matrix = np.zeros((total_speakers,total_speakers))\n",
    "\n",
    "\n",
    "  for itr1 in range(0,len(all_speakers)):\n",
    "      \n",
    "      wavs=glob.glob(all_speakers[itr1]+'/*.wav')\n",
    "      \n",
    "      spk=(all_speakers[itr1]).split(\"/\")[-1]\n",
    "      \n",
    "      if not os.path.exists(directory):\n",
    "          os.makedirs(directory)\n",
    "      \n",
    "      final_feat=np.empty([0, 39])\n",
    "      output = {\"Test_i\":[],\"Accent\":[]}\n",
    "      for itr2 in range(0,len(wavs)):\n",
    "          #print(wavs[itr2])\n",
    "\n",
    "          \n",
    "          feat = eng.prosody(wavs[itr2])\n",
    "          \n",
    "          final_feat=np.concatenate((final_feat,feat),axis=0)\n",
    "          \n",
    "          #print(final_feat.shape)\n",
    "          max_score=-np.inf\n",
    "          max_spk_name=\"\"\n",
    "          \n",
    "          for modelfile in sorted(glob.glob(trained_model_path+'*.pkl')):\n",
    "              gmm = joblib.load(modelfile) \n",
    "              score=gmm.score(feat)\n",
    "              #print score\n",
    "              if score>max_score:\n",
    "                  max_score,max_spk_name=score,modelfile.replace(trained_model_path,'').replace('.pkl','')\n",
    "\n",
    "          print(spk+\" -> \"+max_spk_name+(\" Y\" if spk==max_spk_name  else \" N\"))\n",
    "          output [\"Test_i\"].append(wavs[itr2])\n",
    "          output [\"Accent\"].append(max_spk_name)\n",
    "          confusion_matrix[ spk_names[spk] ][spk_names[max_spk_name]]+=1\n",
    "          tct[spk]+=1\n",
    "\n",
    "          \n",
    "      #print(spk)\n",
    "      json_object = json.dumps(output, indent = 4)\n",
    "      with open(\"Haram.json\", \"w\") as outfile:\n",
    "            outfile.write(json_object)\n",
    "            \n",
    "      np.savetxt(feat_test+spk+\"_all_features.txt\", feat, delimiter=\",\")\n",
    "  return tct,confusion_matrix,total_speakers\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat='/feat/'\n",
    "feat_train='/train/'\n",
    "feat_test='/test/'\n",
    "trained_model='/train_models/'\n",
    "train_data='/traindata/'\n",
    "test_data='/testdata/'\n",
    "\n",
    "# for removing existing feature folders, models created\n",
    "if os.path.exists('/feat/'):\n",
    "  !rm -rf '/feat/'\n",
    "if os.path.exists('/train_models/'):\n",
    "  !rm -rf '/train_models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Completed\n"
     ]
    }
   ],
   "source": [
    "training(train_data,feat_train,trained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "tt,conf_mat,tot_spek=testing(test_data,feat_test,trained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "Confusion Matrix:\n",
      " []\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Dev\\AccentDetection\\GMM.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Dev/AccentDetection/GMM.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(tt)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Dev/AccentDetection/GMM.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mConfusion Matrix:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,conf_mat)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Dev/AccentDetection/GMM.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy: \u001b[39m\u001b[39m\"\u001b[39m,(\u001b[39msum\u001b[39;49m([ conf_mat[i][j] \u001b[39mif\u001b[39;49;00m i\u001b[39m==\u001b[39;49mj  \u001b[39melse\u001b[39;49;00m \u001b[39m0\u001b[39;49m \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(tot_spek) \u001b[39mfor\u001b[39;49;00m j \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(tot_spek) ] )\u001b[39m*\u001b[39;49m\u001b[39m100\u001b[39;49m)\u001b[39m/\u001b[39;49m\u001b[39mfloat\u001b[39;49m(\u001b[39msum\u001b[39;49m([i \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m tt\u001b[39m.\u001b[39;49mvalues()])))\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "print(tt)\n",
    "print(\"Confusion Matrix:\\n\",conf_mat)\n",
    "print(\"Accuracy: \",(sum([ conf_mat[i][j] if i==j  else 0 for i in range(tot_spek) for j in range(tot_spek) ] )*100)/float(sum([i for i in tt.values()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
